{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd7613-58d3-4a3a-a7d1-e4c050eb86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1) Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82eff630-f17a-4e30-8f90-27aebc18052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In machine learning, overfitting and underfitting are two common problems that can occur when training a model.\n",
    "\n",
    "#Overfitting occurs when the model learns the training data too well and is unable to generalize to new data. This can happen when the model is too complex or\n",
    "#when the training data is not representative of the real world data.\n",
    "#Underfitting occurs when the model does not learn the training data well enough and is unable to make accurate predictions. This can happen when the model is \n",
    "#too simple or when the training data is not large enough.\n",
    "\n",
    "#The consequences of overfitting and underfitting can be significant. In the case of overfitting, the model may perform well on the training data but poorly on new data.\n",
    "#This can lead to inaccurate predictions and poor decision-making. In the case of underfitting, the model may perform poorly on both the training data and new data. \n",
    "#This can lead to inaccurate predictions and poor decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95625297-58aa-49e6-b9b0-dc57e4d3c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d6aad2a-a605-4f88-81fb-14b9d00628f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ways to reduce overfitting \n",
    "\n",
    "#Use regularization: Regularization adds a penalty to the model's loss function that discourages the model from becoming too complex. \n",
    "#This can help to prevent the model from overfitting to the training data.\n",
    "\n",
    "#Use early stopping: Early stopping stops the training process early, before the model has had a chance to overfit to the training data.\n",
    "\n",
    "#This can help to assess the model's performance on unseen data and to identify overfitting.\n",
    "\n",
    "#Get more data: More data can help the model learn the underlying patterns in the data and to generalize better to new data.\n",
    "\n",
    "#Simplify the model: A simpler model is less likely to overfit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5091334f-250d-475a-80ab-b6260fb7d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02434b77-71e3-48d7-8518-ae20e8710bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Underfitting is a problem that occurs when a machine learning model is too simple to capture the underlying patterns in the data.\n",
    "#This can lead to poor performance on both the training and test data.\n",
    "#The model is not complex enough. If the model is not complex enough, it will not be able to capture the underlying patterns in the data.\n",
    "\n",
    "#The training data is not representative of the real world data. If the training data is not representative of the real world data, \n",
    "#the model will not be able to generalize well to new data.\n",
    "\n",
    "#The model has not been trained for long enough. If the model has not been trained for long enough, it may not have had enough time to learn the underlying patterns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1775ead-7e98-4dc0-82cd-2fb1cff22aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "# variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff43da13-eb81-4a6e-8e18-89ffa81e6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The bias-variance tradeoff is a fundamental concept in machine learning that describes the relationship between the bias and variance of a model and\n",
    "#its ability to generalize to unseen data. A model with high bias will be simple and will likely underfit the data,\n",
    "#while a model with high variance will be complex and will likely overfit the data. \n",
    "#The goal is to find a model with a balance of bias and variance that minimizes the overall error on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791463b5-fb25-4f93-b47c-effe8c22658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8b4a11-6b40-48c2-970c-aa47b73d2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some common methods for detecting overfitting and underfitting in machine learning models:\n",
    "\n",
    "#Hold out a validation set. This is the most common method for detecting overfitting. The model is trained on a training set and then evaluated on a validation \n",
    "#set that was not used in training. If the model performs significantly better on the training set than on the validation set, then it is likely overfitting.\n",
    "\n",
    "#Use cross-validation. Cross-validation is a more sophisticated method for evaluating a model that involves training the model on multiple subsets of the training data \n",
    "#and then evaluating it on each subset. This helps to reduce the variance of the model's performance and can make it easier to detect overfitting.\n",
    "#Look at the learning curve. The learning curve is a graph of the model's performance on the training set and the validation set as a function of the number of training epochs.\n",
    "#If the learning curve plateaus or starts to decrease on the validation set, then it is likely that the model is overfitting.\n",
    "\n",
    "#Use regularization. Regularization is a technique that penalizes the model for complexity, which can help to reduce overfitting. There are many different regularization techniques, \n",
    "#such as L1 regularization and L2 regularization.\n",
    "\n",
    "#To determine whether your model is overfitting or underfitting, you can use a combination of these methods. If the model performs significantly better on the training \n",
    "#set than on the validation set, then it is likely overfitting. If the model performs poorly on both the training set and the validation set, \n",
    "#then it is likely underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427663a-f961-4ffa-b7cb-3d598acbc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "# and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bcebed2-e8f9-4a01-969f-0642fb53e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bias is the error between the model's predictions and the true values.\n",
    "#Variance is the amount that the model's predictions vary when trained on different data sets.\n",
    "#A model with low bias and low variance will generalize well to unseen data.\n",
    "\n",
    "#Examples of high bias models\n",
    "#Linear regression,Decision trees\n",
    "\n",
    "#Examples of high variance models\n",
    "#Neural networks, Support vector machines\n",
    "\n",
    "#In terms of their performance, models with high bias tend to underfit the data, while models with high variance tend to overfit the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28d46ea-ed53-41a9-b5ca-7ef458e36540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9691d8a-3bc6-4a2c-82c5-689c60ff3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization is a technique used in machine learning to prevent overfitting. Overfitting occurs when a model is too complex and learns the training data too well, \n",
    "#resulting in poor performance on unseen data. Regularization penalizes the model for complexity, which can help to reduce overfitting.\n",
    "# There are many different regularization techniques, but some of the most common include:\n",
    "\n",
    "#L1 regularization: L1 regularization adds a penalty to the sum of the absolute values of the model's weights.\n",
    "#This encourages the model to use only the most important features and to shrink the weights of less important features to zero.\n",
    "\n",
    "#L2 regularization: L2 regularization adds a penalty to the sum of the squared values of the model's weights. This also encourages \n",
    "#the model to use only the most important features, but it does not shrink the weights of less important features to zero.\n",
    "\n",
    "#Elastic net regularization: Elastic net regularization is a combination of L1 and L2 regularization. It can be used to achieve a balance between reducing the model's \n",
    "#complexity and preventing it from becoming too sparse (i.e., having too many weights set to zero)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
